{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAD-CAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_CAM(model, processed_image, actual_label, layer_name='block5_conv3'):\n",
    "#     model_grad = tf.keras.Model([model.inputs], \n",
    "#                        [model.get_layer(layer_name).output, model.output])\n",
    "    \n",
    "#     with tf.GradientTape() as tape:\n",
    "#         conv_output_values, predictions = model_grad(processed_image)\n",
    "\n",
    "#         # watch the conv_output_values\n",
    "#         tape.watch(conv_output_values)\n",
    "\n",
    "#         ## Use binary cross entropy loss\n",
    "#         ## actual_label is 0 if cat, 1 if dog\n",
    "#         # get prediction probability of dog\n",
    "#         # If model does well, \n",
    "#         # pred_prob should be close to 0 if cat, close to 1 if dog\n",
    "#         pred_prob = predictions[:,1] \n",
    "        \n",
    "#         # make sure actual_label is a float, like the rest of the loss calculation\n",
    "#         actual_label = tf.cast(actual_label, dtype=tf.float32)\n",
    "        \n",
    "#         # add a tiny value to avoid log of 0\n",
    "#         smoothing = 0.00001 \n",
    "        \n",
    "#         # Calculate loss as binary cross entropy\n",
    "#         loss = tf.keras.losses.CategoricalCrossentropy(actual_label, pred_prob)\n",
    "#         print(f\"Categorical Crossentropy loss: {loss}\")\n",
    "    \n",
    "#     # get the gradient of the loss with respect to the outputs of the last conv layer\n",
    "#     grads_values = tape.gradient(loss, conv_output_values)\n",
    "#     grads_values = tf.keras.backend.mean(grads_values, axis=(0,1,2))\n",
    "    \n",
    "#     conv_output_values = np.squeeze(conv_output_values.numpy())\n",
    "#     grads_values = grads_values.numpy()\n",
    "    \n",
    "#     # weight the convolution outputs with the computed gradients\n",
    "#     for i in range(512): \n",
    "#         conv_output_values[:,:,i] *= grads_values[i]\n",
    "#     heatmap = np.mean(conv_output_values, axis=-1)\n",
    "    \n",
    "#     heatmap = np.maximum(heatmap, 0)\n",
    "#     heatmap /= heatmap.max()\n",
    "    \n",
    "#     del model_grad, conv_output_values, grads_values, loss\n",
    "   \n",
    "#     return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gap_weights = model.layers[-5].get_weights()[0]\n",
    "# gap_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gap_weights = model.layers[-1].get_weights()[0]\n",
    "# gap_weights.shape\n",
    "\n",
    "# cam_model = tf.keras.Model(\n",
    "#     inputs=model.input,\n",
    "#     outputs=(model.layers[-4].output,model.layers[-1].output)\n",
    "# )\n",
    "# cam_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gap_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_cam(image_value, features, results):\n",
    "#   '''\n",
    "#   Displays the class activation map of an image\n",
    "\n",
    "#   Args:\n",
    "#     image_value (tensor) -- preprocessed input image with size 300 x 300\n",
    "#     features (array) -- features of the image, shape (1, 37, 37, 128)\n",
    "#     results (array) -- output of the sigmoid layer\n",
    "#   '''\n",
    "\n",
    "#   # there is only one image in the batch so we index at `0`\n",
    "#   features_for_img = features[0]\n",
    "#   prediction = results[0]\n",
    "\n",
    "#   # there is only one unit in the output so we get the weights connected to it\n",
    "#   class_activation_weights = gap_weights[:,0]\n",
    "\n",
    "#   # upsample to the image size\n",
    "#   class_activation_features = sp.ndimage.zoom(features_for_img, (IMAGE_SIZE[0]/14, IMAGE_SIZE[1]/14, 1), order=2)\n",
    "  \n",
    "#   # compute the intensity of each feature in the CAM\n",
    "#   cam_output  = np.dot(class_activation_features, class_activation_weights)\n",
    "\n",
    "#   # visualize the results\n",
    "#   print(f'sigmoid output: {results}')\n",
    "#   print(f\"prediction: {'dog' if round(results[0][0]) else 'cat'}\")\n",
    "#   plt.figure(figsize=(8,8))\n",
    "#   plt.imshow(cam_output, cmap='jet', alpha=0.5)\n",
    "#   plt.imshow(tf.squeeze(image_value), alpha=0.5)\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, labels in validation_set.take(1):\n",
    "#   for i in range(2):\n",
    "#     # get the features and prediction\n",
    "#     features, results = cam_model.predict(images)\n",
    "    \n",
    "#     # generate the CAM\n",
    "#     show_cam(images, features, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('bo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4484fdc5993b177ce97364fa408f1d1e72c623384181aa31524f294720741f08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
