{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activation Maps (CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_model.layers[-3]\n",
    "# augment_model.layers[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam_model = tf.keras.Model(\n",
    "#     inputs=augment_model.input,\n",
    "#     outputs=(augment_model.layers[-5].output, augment_model.layers[-1].output)\n",
    "# )\n",
    "# cam_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features, results = cam_model.predict(val_ds)\n",
    "\n",
    "# # shape of the features\n",
    "# print(\"features shape: \", features.shape)\n",
    "# print(\"results shape\", results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # these are the weights going into the softmax layer\n",
    "# last_dense_layer = augment_model.layers[-1]\n",
    "\n",
    "# # get the weights list.  index 0 contains the weights, index 1 contains the biases\n",
    "# gap_weights_l = last_dense_layer.get_weights()\n",
    "\n",
    "# print(\"gap_weights_l index 0 contains weights \", gap_weights_l[0].shape)\n",
    "# print(\"gap_weights_l index 1 contains biases \", gap_weights_l[1].shape)\n",
    "\n",
    "# # shows the number of features per class, and the total number of classes\n",
    "# # Store the weights\n",
    "# gap_weights = gap_weights_l[0]\n",
    "\n",
    "# print(f\"There are {gap_weights.shape[0]} feature weights and {gap_weights.shape[1]} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the features for the image at index 0\n",
    "# idx = 0\n",
    "# features_for_img = features[idx,:,:,:]\n",
    "\n",
    "# print(f\"The features for image index {idx} has shape (height, width, num of feature channels) : \", features_for_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_for_img_scaled = sp.ndimage.zoom(features_for_img, (224/52, 224/52, .5), order=2)\n",
    "\n",
    "# # Check the shape after scaling up to 28 by 28 (still 128 feature channels)\n",
    "# print(\"features_for_img_scaled up to 28 by 28 height and width:\", features_for_img_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the weights that are used for a specific class (0...9)\n",
    "# class_id = 0\n",
    "# # take the dot product between the scaled image features and the weights for \n",
    "# gap_weights_for_one_class = gap_weights[:,class_id]\n",
    "\n",
    "# print(\"features_for_img_scaled has shape \", features_for_img_scaled.shape)\n",
    "# print(\"gap_weights_for_one_class has shape \", gap_weights_for_one_class.shape)\n",
    "# # take the dot product between the scaled features and the weights for one class\n",
    "# cam = np.dot(features_for_img_scaled, gap_weights_for_one_class)\n",
    "\n",
    "# print(\"class activation map shape \", cam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_cam(image_index):\n",
    "#     features_for_image = features[image_index,:,:,:]\n",
    "#     prediction = np.argmax(results[image_index])\n",
    "#     class_activation_weights = gap_weights[:, prediction]\n",
    "#     class_activation_features = sp.ndimage.zoom(features_for_image, (28/3, 28/3, 1), order=2)\n",
    "#     cam_output = np.dot(class_activation_features, class_activation_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_cam(image_index):\n",
    "#   '''displays the class activation map of a particular image'''\n",
    "\n",
    "#   # takes the features of the chosen image\n",
    "#   features_for_img = features[image_index,:,:,:]\n",
    "\n",
    "#   # get the class with the highest output probability\n",
    "#   prediction = np.argmax(results[image_index])\n",
    "\n",
    "#   # get the gap weights at the predicted class\n",
    "#   class_activation_weights = gap_weights[:,prediction]\n",
    "\n",
    "#   # upsample the features to the image's original size (28 x 28)\n",
    "#   class_activation_features = sp.ndimage.zoom(features_for_img, (224/52, 224/52, .5), order=2)\n",
    "\n",
    "#   # compute the intensity of each feature in the CAM\n",
    "#   cam_output  = np.dot(class_activation_features,class_activation_weights)\n",
    "  \n",
    "#   print('Predicted Class = ' +str(prediction)+ ', Probability = ' + str(results[image_index][prediction]))\n",
    "  \n",
    "#   # show the upsampled image\n",
    "#   plt.imshow(np.squeeze(val_ds[image_index],-1), alpha=0.5)\n",
    "  \n",
    "#   # strongly classified (95% probability) images will be in green, else red\n",
    "#   if results[image_index][prediction]>0.95:\n",
    "#     cmap_str = 'Greens'\n",
    "#   else:\n",
    "#     cmap_str = 'Reds'\n",
    "\n",
    "#   # overlay the cam output\n",
    "#   plt.imshow(cam_output, cmap=cmap_str, alpha=0.5)\n",
    "\n",
    "#   # display the image\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_maps(desired_class, num_maps):\n",
    "#     '''\n",
    "#     goes through the first 10,000 test images and generates CAMs \n",
    "#     for the first `num_maps`(int) of the `desired_class`(int)\n",
    "#     '''\n",
    "\n",
    "#     counter = 0\n",
    "\n",
    "#     if desired_class < 10:\n",
    "#         print(\"please choose a class less than 10\")\n",
    "\n",
    "#     # go through the first 10000 images\n",
    "#     for i in range(0,10000):\n",
    "#         # break if we already displayed the specified number of maps\n",
    "#         if counter == num_maps:\n",
    "#             break\n",
    "\n",
    "#         # images that match the class will be shown\n",
    "#         if np.argmax(results[i]) == desired_class:\n",
    "#             counter += 1\n",
    "#             show_cam(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_maps(desired_class=3, num_maps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('bo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4484fdc5993b177ce97364fa408f1d1e72c623384181aa31524f294720741f08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
