{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import ViTFeatureExtractor, TFViTForImageClassification\n",
    "\n",
    "tf.keras.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'google/vit-base-patch16-224'\n",
    "model = TFViTForImageClassification.from_pretrained(model_path)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_path)\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in temp_set.take(1):\n",
    "    print(tf.shape(feature_extractor(image[0].numpy(), return_tensors='tf')['pixel_values']))\n",
    "    print(feature_extractor(image[0].numpy()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    print(example[0])\n",
    "    inputs = feature_extractor(example[0].numpy(), return_tensors='tf')\n",
    "    # print(inputs)\n",
    "    inputs['labels'] = example[1]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_set = training_set.map(lambda x, y: (tf.experimental.numpy.moveaxis(x, -1, 1), y)) \n",
    "# valid_set = validation_set.map(lambda x, y: (tf.experimental.numpy.moveaxis(x, -1, 1), y))\n",
    "\n",
    "# temp_set = temp_set.map(lambda x, y: process_example([x,y])) \n",
    "# valid_set = valid_set.map(lambda x, y: process_example([x,y])) \n",
    "\n",
    "# # results = []\n",
    "# # for image,label in temp_set.take(1):\n",
    "# #     results.append(process_example([image, label]))\n",
    "# #     # print(tf.shape(data[1]))\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "pixel_values = tf.keras.layers.Input(shape=(3,224,224), name='pixel_values', dtype='float32')\n",
    "\n",
    "# model layer\n",
    "vit = model.vit(pixel_values)[0]\n",
    "classifier = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(vit[:, 0, :])\n",
    "\n",
    "# model\n",
    "keras_model = tf.keras.Model(inputs=pixel_values, outputs=classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(examples):\n",
    "\n",
    "    print(examples.shape)\n",
    "    images = examples['img']\n",
    "    images = [np.array(image, dtype=np.uint8) for image in images]\n",
    "    images = [np.moveaxis(image, source=-1, destination=0) for image in images]\n",
    "    inputs = feature_extractor(images=images)\n",
    "    examples['pixel_values'] = inputs['pixel_values']\n",
    "\n",
    "    return examples.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_set = training_set.map(lambda x, y: (tf.experimental.numpy.moveaxis(x, -1, 1), y)) \n",
    "valid_set = validation_set.map(lambda x, y: (tf.experimental.numpy.moveaxis(x, -1, 1), y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Compiling the model\n",
    "keras_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "vit_history = keras_model.fit(\n",
    "  temp_set,\n",
    "  validation_data=valid_set,\n",
    "  epochs=EPOCHS\n",
    ")\n",
    "\n",
    "elasped_time = time.time() - start_time\n",
    "model_elapsed_time[\"vit\"] = elasped_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('bo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4484fdc5993b177ce97364fa408f1d1e72c623384181aa31524f294720741f08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
